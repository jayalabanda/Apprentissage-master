{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"float:right; max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Scénarios d'Apprentissage Statistique](https://github.com/wikistat/Apprentissage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détection de pourriels avec <a href=\"https://cran.r-project.org/\"><img src=\"https://cran.r-project.org/Rlogo.svg\" style=\"max-width: 40px; display: inline\" alt=\"R\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résumé \n",
    "Après l'[exploration](https://github.com/wikistat/Ewploration/tree/master/Spam) et la classification des contenus d'une base de messages électroniques afin de catégoriser les pourriels, il s'agit de construire des *scores* ou modèles prévoyant la nature d'un message: pourriel ou non, en fonction de son contenu ou plutôt de la présence ou fréquence de certains mots et caractères. Les principales méthodes de modélisation et [apprentissage statistique](http://wikistat.fr/pdf/st-m-app-intro.pdf) sont testées et comparées, la librairie `caret` est utilisée pour automatiser les traitements.\n",
    "\n",
    "\n",
    "\n",
    "## Introduction\n",
    "### Objectif\n",
    "Cette étude est un exemple d'analyse textuelle d'un corpus de documents, ici des courriels. Une telle analyse est classiquement basée sur la fréquence d'une sélection de mots. Après l'[analyse exploratoire](https://github.com/wikistat/Ewploration/tree/master/Spam), l'objectif général est de pouvoir discriminer les courriels pertinents ou encore de définir un modèle personnalisé de *détection  des pourriels* (spams), c'est-à-dire adapté au contenu spécifique de la boîte d'un internaute. Il s'agit donc d'un modèle susceptible de prévoir la *qualité* d'un message reçu en fonction de son contenu. Le déroulement de cette étude est évidemment marqué par le type particulier des données mais celle-ci peut facilement se transposer à d'autres types de données textuelles ou analyse du contenu de livres, pages web, discours politiques, réponses ouvertes à des questionnaires... les exemples sont nombreux en sciences humaines, marketing lorsqu'il s'agit d'estimer / prévoir des scores, par exemple, de satisfaction de clientèle.\n",
    "\n",
    "L'objectif du présent travail est d'évaluer, comparer différentes stratégies et méthodes pour aboutir à celle la plus efficace de filtrage des courriers indésirables. Il s'agit de déterminer quelle méthode de modélisation parmi celles concurrentes: logit, arbre, réseau de neurones, random forest, boosting, SVM, se montre la plus efficace.\n",
    "\n",
    "### Données\n",
    "George, ingénieur chez HP dans le département *Computer Science* a recueilli un échantillon de messages électroniques dans chacun desquels il a évalué le nombre d'occurrences d'une sélection de mots et caractères. Les variables considérées sont, dans une première partie, des rapports: nombre d'occurrences d'un mot spécifique sur le nombre total de mots ou nombre d'occurrences d'un caractère sur le nombre de caractères du message avant d'être, dans une deuxième partie, des indicatrices ou facteurs: présence / absence de mots ou ensemble de caractères. Il a également considéré trois variables prenant en compte la casse (majuscule / minuscule) des caractères et une dernière qualitative binaire indiquant le classement qu'il a fait de chaque message : `spam` ou `Nsp`. Les variables d'occurrences sont décrites dans le tableau 1, celles associées à la casse dans le tableau 2. Ces données sont publiques, elles servent régulièrement de *benchmark* pour la comparaison de méthodes d'apprentissage machine:\n",
    "\n",
    "Frank A., Asuncion A. (2010). [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml). Irvine, CA: University of California, School of Information and Computer Science.\n",
    "\n",
    "Ce sont donc finalement 58 variables qui sont observées sur 4601 messages dont 1813 pourriels (spams). La variable binaire `Spam` est présente à titre illustratif, elle est toujours considérée en supplémentaire dans ce travail exploratoire préliminaire. \n",
    "\n",
    "\n",
    "Le tableau ci-dessous liste 54 variables exprimant soit:\n",
    "- le rapport du nombre d'occurrence d'un mot (resp. de caractères) sur le nombre total de mots (de caractères) dans un message,\n",
    "- soit la présence ou non de ce mot (resp. caractère) dans le message, \n",
    "- des numéros (85...) qui sont ceux de bureau, téléphone, code postal de George.\n",
    "\n",
    "\n",
    "*Tableau 1:  Les colonnes contiennent successivement le libellé de la variable, le mot ou ensemble de caractères concernés, le libellé des modalités Présence / Absence utilisées après recodage.*\n",
    "\n",
    "Variable   | Mot ou Carac |    Modalités P/A   | Variable   | Mot ou Carac. |   Modalités  \n",
    "  --|-- --|-- --|-- --|-- --|--               \n",
    "make |    make |   make / Nmk|    X650 |   650 |   650 / N65 \n",
    "address |   address |   addr / Nad |   lab |   lab |   lab / Nlb\n",
    "all |   all |   all / Nal |   labs |   labs |   labs / Nls \n",
    "X3d |   3d |   3d / N3d |   telnet |   telnet |   teln / Ntl \n",
    "our |   our |   our / Nou |   X857 |   857 |   857 / N87 \n",
    "over |   over |   over / Nov |   data |   data |   data / Nda  \n",
    "remove |   remove |   remo / Nrm |   X415 |   415   | 415 / N41 \n",
    "internet |   internet |   inte / Nin |   X85 |   85 |   85 / N85 \n",
    "order |   order |   orde / Nor |   technology |   technology |   tech / Ntc \n",
    "mail |   mail |   mail / Nma |   X1999 |   1999 |   1999/ N19 \n",
    "receive |   receive |   rece / Nrc |   parts |   parts |   part / Npr \n",
    "will |   will |   will / Nwi |   pm |   pm |   pm / Npm \n",
    "people |   people |   peop / Npp |   direct |   direct |   dire / Ndr \n",
    "report |   report |   repo / Nrp |   cs |   cs |   cs / Ncs \n",
    "addresses |   addresses   | adds / Nas |   meeting |   meeting |   meet/Nmt \n",
    "free |   free |   free / Nfr |   original |   original |   orig / or \n",
    "business |   business |   busi / Nbs |   project |   project |   proj / Npj \n",
    "email |   email |   emai / Nem |   re |   re |   re / Nre \n",
    "you |   you |   you / Nyo |   edu |   edu |   edu / Ned \n",
    "credit |   credit |   cred / Ncr |   table    | table |   tabl / Ntb \n",
    "your |   your |   your / Nyr |   conference |   conferenc |e   conf / Ncf \n",
    "font |   order |   font / Nft |   CsemiCol |   ; |   Cscl / NCs \n",
    "X000 |   000 |   000 / N00 |   Cpar |   (    | Cpar / NCp \n",
    "money |   money |   mone/ Nmn |   Ccroch |   [    | Ccro / NCc \n",
    "hp |   hp |   hp / Nhp |   Cexclam |    ! |   Cexc / NCe \n",
    "hpl |   hpl |   hpl / Nhl |   Cdollar |   \\$ |   Cdol / NCd  \n",
    "george |   george |   geor / Nge |   Cdiese | # |   Cdie / NCi  \n",
    "\n",
    "\n",
    "\n",
    "Un deuxième tableau liste 4 variables dont celle dénombrant le nombre de lettres majuscules.\n",
    "\n",
    "\n",
    "*Tableau 2:Liste de 4 variables, de leur libellé et des modalités après recodage.*\n",
    "\n",
    "Code variable | Libellé | Modalités\n",
    "--|-- --|--\n",
    "Spam | Type de message pourriel ou non |  Spam / Nsp\n",
    "CapLM |\tNombre moyen de capitales par mot |  Mm1 / Mm2 / Mm3\n",
    "CapLsup\t| Nombre max de capitales par mot | Ms1 / Ms2 / Ms3 \n",
    "CapLtot\t| Nombre totale de lettres capitales |\tMt1 / Mt2 / Mt3 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Déroulement\n",
    "Cette étude nécessite une série d'étapes afin de mettre en oeuvre les comparaisons recherchées.\n",
    "- lecture des données et extraction des échantillons, \n",
    "- comparaison de deux stratégie utilisant la régression logistique: variables codées en classe ou variables brutes réelles?\n",
    "- Comparaison automatisée de différentes méthodes ou algorithmes: régression logistique avec sélection de variable, analyse discriminante ou knn, arbre de classification, réseau de neurones, random forest, boosting, SVM, *extrem gradient boosting* (`XGBoost`).\n",
    "- La procédure d'extraction aléatoire d'un échantillon test est itérée de façon à optenir plusieurs estimations des erreurs de prévision. Comparaison des distributions des erreurs et tracé des courbes ROC.\n",
    "- Synthèse et conclusion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gestion des données\n",
    "Les données sont disponibles sous deux formes dans le même répertoire que ce calepin:  fréquences quantitatives  dans le fichier `spam.dat` et recodées en classes dans le fichier `spamq.dat`. Les lire avec les commandes suivantes: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spamq=read.table(\"spamq.dat\")\n",
    "summary(spamq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spamr=read.table(\"spam.dat\",header=T)\n",
    "summary(spamr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extractions des échantillons d'apprentissage (`spamq.appt`) et de test (`spamq.test`) dans le cas qualitatif, `spamr.appt` et `spamr.test` dans le cas quantitatif."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choisir une valeur entière pour \"xx\"\n",
    "xx=...\n",
    "set.seed(xx)\n",
    "npop=nrow(spamq)\n",
    "test=sample(1:npop,1000) \n",
    "spamq.test=spamq[test,]\n",
    "appt=setdiff(1:npop,test)\n",
    "spamq.appt=spamq[appt,]\n",
    "spamr.test=spamr[test,]\n",
    "spamr.appt=spamr[appt,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les échantillons tests sont identiques afin de pouvoir mieux comparer les résultats.\n",
    "\n",
    "La taille de l'échantillon initial relativement importante permettrait d'extraire un autre échantillon de validation surlequel serait minimiser les erreurs de prévision afin d'optimiser la complexité des modèles. Cette stratégie mise en oeuvre par défaut dans *SAS Enterprise Miner* s'avère dans R finalement plus compliquée à exécuter, que celle utilisant systématiquement la validation croisée, sans bénéfice notable sur la qualité des optimisations (cf. le [tutoriel](https://www.math.univ-toulouse.fr/~besse/Wikistat/pdf/st-scenar-app-spam.pdf)). C'est donc la validation croisée qui est privilégiée dans la recherche de modèle optimaux.\n",
    "\n",
    "Plusieurs approches peuvent être comparées selon le type de données ou de transformation des données pris en compte:\n",
    "- variables quantitatives des nombres d'occurrence,\n",
    "- variables qualitatives des absence / présence,\n",
    "- composantes issues d'une afcm ou d'une décomposition par NMF (cf. le tutoriel d'[exploration](https://github.com/wikistat/Ewploration/tree/master/Spam)),\n",
    "- variables des fréquences pondérées ou [TF-IDF]().\n",
    "- un mélange de toutes ces variables...\n",
    "Seuls les deux premiers cas sont traités pour la seule régression logistique. \n",
    "\n",
    "**Q** Quel intérêt pour la régression logistique de considérer des variables qualitatives obtenues par découpage en classe de variables quantitatives?\n",
    "\n",
    "**Q** Corrélativement, pourquoi les méthodes basées sur des arbres de décision ont pus intérêt à prendre en compte les variables quantitatives initiales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Régression logistique](http://wikistat.fr/pdf/st-m-app-rlogit.pdf)\n",
    "### Données quantitatives ou qualitatives? \n",
    "La régression logistique est détaillée en utilisant deux [algorithmes de sélections de variables](http://wikistat.fr/pdf/st-m-app-linSelect.pdf) basés sur une pénalisation AIC (*backward* et *stepwise*).\n",
    "\n",
    "Ces algorihtmes de sélection seraient à comparer avec ceux utilisant une [pénalisation Lasso](http://wikistat.fr/pdf/st-m-app-linSelect.pdf) qui sont systématiquement utilisés dans la librairie `Scikit-learn` de Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les modèles trop complexes génèrent de très nombreux *warnings* dus à des estimations de probabilités 0 ou 1 pour certaines observations. \n",
    "\n",
    "les *warnings* sont temporairement supprimés:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "oldw <- getOption(\"warn\")\n",
    "options(warn = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spamq.logit1=glm(spamf~.,data=spamq.appt,family=binomial)\n",
    "spamq.log1=step(spamq.logit1,direction='backward', trace=0)\n",
    "spamq.logit2=glm(spamf~1,data=spamq.appt,family=binomial)\n",
    "spamq.log2=step(spamq.logit2,direction='both',\n",
    "   scope=list(lower=~1,upper=~make + address + \n",
    "   all + X3d + our + over + remove + internet + \n",
    "   order + mail + receive + will + people + \n",
    "   report + addresses + free + business + \n",
    "   email + you + credit + your + font + X000 + \n",
    "   money + hp + hpl + george + X650 + lab + \n",
    "   labs + telnet +  X857 + data + X415 + X85 + \n",
    "   technology + X1999 + parts + pm + direct + \n",
    "   cs + meeting + original + project + re + \n",
    "   edu + table + conference + CsemiCol + \n",
    "   Cpar + Ccroch + Cexclam + Cdollar + \n",
    "   Cdiese + CapLMq + CapLsupq + CapLtotq), trace=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'option `trace=0` supprime les sorties très volumineuses lorsque le nombre de variables est important.\n",
    "\n",
    "Comparer les performances des deux modèles par validation croisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(boot)\n",
    "cv.glm(spamq.appt,spamq.log1,K=10)$delta[1] \n",
    "cv.glm(spamq.appt,spamq.log2,K=10)$delta[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retenir le meilleur modèle disons `spamq.log2` mais cela dépend de l'échantillon d'apprentissage tiré. \n",
    "\n",
    "La commande:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anova(spamq.log2,test=\"Chisq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "permet d'identifier la variable la moins significative du modèle. Il serait alors possible de retirer cette variable du modèle, le ré-estimer avant de vérifier si l'erreur de prévision sur l'échantillon de validation est améliorée ou pas, ... itérer ou non cette démarche.\n",
    "\n",
    "Même chose avec les variables quantitatives. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spamr.logit1=glm(spam~.,data=spamr.appt,family=binomial)\n",
    "spamr.log1=step(spamr.logit1,direction='backward', trace=0)\n",
    "\n",
    "spamr.logit2=glm(spam~1,data=spamr.appt,family=binomial)\n",
    "spamr.log2=step(spamr.logit2,direction='both',\n",
    "   scope=list(lower=~1,upper=~make + address + \n",
    "   all + X3d + our + over + remove + internet + \n",
    "    order + mail + receive + will + people + \n",
    "    report + addresses + free + business + \n",
    "    email + you + credit + your + font + X000 + \n",
    "    money + hp + hpl + george + X650 + lab + \n",
    "    labs + telnet + X857 + data + X415 + X85 + \n",
    "    technology + X1999 + parts + pm + direct + \n",
    "    cs + meeting + original + project + re + \n",
    "    edu + table + conference + CsemiCol + \n",
    "    Cpar + Ccroch + Cexclam + Cdollar + \n",
    "    Cdiese + CapLM + CapLsup + CapLtot),trace=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparer les modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(boot)\n",
    "cv.glm(spamr.appt,spamr.log1,K=10)$delta[1] \n",
    "cv.glm(spamr.appt,spamr.log2,K=10)$delta[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# retour des warnings\n",
    "options(warn = oldw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimiser éventuellement le choix opéré en tâchant de réduire l'erreur par validation croisée par le retrait des variables les moins significatives du modèle.\n",
    "\n",
    "Appliquer le meilleur modèle obtenu à l'achantillon test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.log=predict(spamq.log2,newdata=spamq.test)\n",
    "table(pred.log>0.5,spamq.test[,\"spamf\"]) # 0.065"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.log=predict(spamr.log2,newdata=spamr.test)\n",
    "table(pred.log>0.5,spamr.test[,\"spam\"]) # 0.065"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quelle ensemble de variables retenir: qualitatives ou quantitatives, pour la régression logistique?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparaison systématique des méthodes\n",
    "La suite du travail se propose d'utiliser la librairie `caret`[(Kuhn, 2008)](https://www.jstatsoft.org/article/view/v028i05) afin de faciliter et *industrialiser* les traitements. Attention, cette librairie fait appel à de nombreuses autres librairies qui doivent être installées à la demande. La version \"artisanale\" des commandes, sans l'utilisation de `caret` est proposée en annexe. \n",
    "\n",
    "### Calcul parallèle\n",
    "Même sous windows, `caret` offre simplement des possibilités de parallèlisation en utilisant la package `doParallel`. Même si les algorithmes des différentes méthodes d'apprentissage ne sont pas parallélisés, les itérations des calculs de validation croisée pour l'optimisation des paramètres le sont avec un gain de temps très appréciable fonction du nombre de processeurs. Ceci est obtenu en exécutant les commandes suivantes en supposant que 4 processeurs sont disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(doParallel)\n",
    "cl <- makeCluster(4)\n",
    "registerDoParallel(cl) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des données\n",
    "Les données sont celles brutes c'est-à-dire quantitatives et la stratégie adoptée pour optimiser les modèles est la validation croisée. D'autres choix sont possibles (bootstrap). La librairie `caret` intègre des fonctions d'échantillonnage et de normalisation des données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "require(caret)\n",
    "# extraction des données\n",
    "# remplacer les niveaux \"0\" et \"1\" \n",
    "# par \"nospam\" et \"spam\"\n",
    "Y=rep(\"spam\",nrow(spamr))\n",
    "Y[spamr[,1]==0]=\"nospam\"\n",
    "Y=as.factor(Y)\n",
    "summary(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=spamr[,-1]\n",
    "summary(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# indices de l'échantillon d'apprentissage\n",
    "set.seed(xx)\n",
    "inTrain = createDataPartition(X[,1],p = 78/100, list = FALSE)\n",
    "# Extraction des échantillons\n",
    "trainDescr=X[inTrain,]\n",
    "testDescr=X[-inTrain,]\n",
    "trainY=Y[inTrain]\n",
    "testY=Y[-inTrain]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary(trainY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est recommandé de centrer et réduire les variables dans plusieurs méthodes. C'est fait systématiquement et simplement en utilisant évidemment les mêmes transformations sur l'échantillon test que celles mises en place sur l'échantillon d'apprentissage. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisation\n",
    "xTrans=preProcess(trainDescr)\n",
    "trainDescr=predict(xTrans,trainDescr)\n",
    "testDescr=predict(xTrans,testDescr)\n",
    "# Choix de la validation croisée\n",
    "cvControl=trainControl(method=\"cv\",number=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il peut arriver sur certains jeux de données qu'après partitionnement de l'échantillon par validation croisée ou bootstrap, certaines variables deviennent strictement constantes sur une classe. Ceci pose des problèmes à certaines méthodes comme l'analyse discriminante ou les classifieurs bayésien naïf car la variance est nulle pour ces variables au sein d'une classe. \n",
    "\n",
    "La librairie `caret` inclut une fonction permettant d'itentifier ces variables en vue de leur suppression. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consulter la documentation\n",
    "?nearZeroVar\n",
    "nearZeroVar(spamr, saveMetrics= TRUE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le problème de ces données textuelles très creuses : beaucoup de mots ne sont pas présents dans la plupart des messages, est que la grande majorité des variables est considérée comme *near zero variance*. Le seuil de décision peut être remonté mais cela n'élimine alors plus le risque de variance constante!\n",
    "\n",
    "### Estimation et optimisation des modèles\n",
    "La librairie intègre beaucoup plus de méthodes et celles sélectionnées ci-dessous semblent les plus pertinentes. Certaines méthodes ne sont pas utilisables à cause du nombre de variables. Il pourrait être utile et intéressant d'en tester encore d'autres.  Exécuter successivement les blocs de commandes pour tracer séparamment chacun des graphes afin de contrôler le bon comportement de l'optimisation du paramètre de complexité de chaque modèle.\n",
    "\n",
    "Consulter la liste des méthodes disponibles dans l'aide de la fonction : `?train` et tester les principales. L'utilisation de certaines comme la régression logistique est moins flexible qu'en utilisation \"manuelle\" en particulier dans le choix de l'algorithme de sélection de variables. Il faut se montrer (très) patient pour certaines optimisations alors que d'autres sont immédiates, voire inutiles. \n",
    "\n",
    "L'expérimenter fait partie de l'expertise à acquérir.\n",
    "\n",
    "**Q** Que signifie: `trControl = cvControl` dans lacommande ci-dessous?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Régression logistique\n",
    "set.seed(2)\n",
    "rlogFit = train(trainDescr, trainY,method = \"glmStepAIC\",trControl = cvControl)\n",
    "rlogFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 analyse discriminante linéaire\n",
    "set.seed(2)\n",
    "ldaFit = train(trainDescr, trainY,method = \"lda2\",trControl = cvControl)\n",
    "ldaFit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Que signifie le paramètre `tuneLength` pour les méthodes suivantes? pourquoi n'est-il pas présent avec la méthode `glmStepAIC`? Quel est son impact?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 K plus proches voisins\n",
    "set.seed(2)\n",
    "knnFit = train(trainDescr, trainY,method = \"knn\", tuneLength = 10,trControl = cvControl)\n",
    "knnFit\n",
    "plot(knnFit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Comment interpréter le graphe précédent?\n",
    "\n",
    "**Q** Quel est le paramètre optimisé pour la méthode suivante?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Arbre de décision\n",
    "set.seed(2)\n",
    "rpartFit = train(trainDescr, trainY, method = \"rpart\", tuneLength = 10,trControl = cvControl)\n",
    "rpartFit\n",
    "plot(rpartFit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quel est le modèle ci-desosus ? Quels sont les paramètres optimisés?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Réseau de neurones\n",
    "set.seed(2)\n",
    "nnetFit = train(trainDescr, trainY,method = \"nnet\", tuneLength = 6,trControl = cvControl)\n",
    "nnetFit\n",
    "plot(nnetFit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quel est le paramètre optimisé de *random forest*?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 Random forest\n",
    "set.seed(2)\n",
    "rfFit = train(trainDescr, trainY,method = \"rf\", tuneLength = 6,trControl = cvControl)\n",
    "rfFit\n",
    "plot(rfFit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quel algorihtme de boosting est utilisé? Quels sont ses paramètres? Quels sont ceux optimisés?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 Boosting d'arbres\n",
    "set.seed(2)\n",
    "gbmFit = train(trainDescr, trainY,method = \"gbm\", tuneLength = 6,trControl = cvControl)\n",
    "gbmFit\n",
    "plot(gbmFit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quels autres paramètres viennent s'ajouter avec l'extrême boosting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8 xgboost ou extrem gradient boosting\n",
    "set.seed(2)\n",
    "xgboostFit = train(trainDescr, trainY,method = \"xgbTree\", tuneLength = 8,trControl = cvControl)\n",
    "plot(xgboostFit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quel noyau est utilisé? Quels sont les paramètres?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#9 Support vector machine avec noyau gaussien\n",
    "set.seed(2)\n",
    "svmgFit = train(trainDescr, trainY,method = \"svmRadial\", tuneLength = 8,trControl = cvControl)\n",
    "svmgFit\n",
    "plot(svmgFit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prévision et erreur en test\n",
    "Les méthodes sélectionnées et optimisées sont ensuite appliquées à la prévision\n",
    "de l'échantillon test. Estimation du taux de bien classés :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=list(knn=knnFit,cart=rpartFit,rf=rfFit,gbm=gbmFit,svmg=svmgFit,xgb=xgboostFit)\n",
    "testPred=predict(models, newdata = testDescr)\n",
    "# taux de bien classés\n",
    "lapply(testPred,function(x)mean(x==testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracer les courbes ROC pour analyser spécificité et sensibilité des différentes méthodes. \n",
    "L'analyse discriminante qui ne fournit pas de probabilités d'occurence de la classe ``spam'' n'est pas adaptée au tracé d'une courbe ROC. Comme elle fait par ailleurs partie des moins performantes sur l'échantillon test, elles est retirée de la liste des modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Courbes ROC\n",
    "library(ROCR)\n",
    "models=list(cart=rpartFit,rf=rfFit,gbm=gbmFit,xgb=xgboostFit)\n",
    "testProb=predict(models, newdata = testDescr,type=\"prob\")\n",
    "predroc=lapply(testProb,function(x)prediction(x[,1],testY==\"nospam\"))\n",
    "perfroc=lapply(predroc,function(x)performance(x, \"tpr\", \"fpr\"))\n",
    "plot(perfroc$cart,col=1)\n",
    "plot(perfroc$rf,col=2,add=TRUE)\n",
    "plot(perfroc$gbm,col=3,add=TRUE)\n",
    "plot(perfroc$xgb,col=4,add=TRUE)\n",
    "legend(\"bottomright\",legend=c(\"CART\",\"RF\",\"boost\",\"XGBoost\"),col=c(1:4),pch=\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Interpréter les résultats obtenus. Quelles sont les méthodes les plus performantes à ce niveau de l'analyse?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importance des variables\n",
    "Les meilleures méthodes (forêts aléatoires, boosting...) sont très peu explicites, car de véritables \"boîtes noires\", quant au rôle et impact des variables sur la prévision des observations. Néanmoins, des indicateurs d'importance sont proposés pour les forêts aléatoires ou `XGBoost`.\n",
    "\n",
    "**Q** comment son définis les indicateurs d'importance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfFit2=randomForest(trainDescr,trainY,importance=T)\n",
    "imp.mdrr=sort(rfFit2$importance[,3],decreasing=T)[1:20]\n",
    "par(xaxt=\"n\")\n",
    "plot(imp.mdrr,type=\"h\",ylab=\"Importance\",xlab=\"Variables\")\n",
    "points(imp.mdrr,pch=20)\n",
    "par(xaxt=\"s\")\n",
    "axis(1,at=1:20,labels=names(imp.mdrr),cex.axis=0.8, las=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatisation\n",
    "L'échantillon est de  taille raisonnable, mais les estimations des taux de bien classés comme le tracé des courbes ROC sont très dépendants de l'échantillon test ; on peut s'interroger sur l'identité du modèle le plus performant comme sur la réalité des différences entre les méthodes. Il est donc important d'itérer le processus sur plusieurs échantillons tests. \n",
    "\n",
    "Exécuter la fonction en annexe en choisissant les méthodes semblant les plus performantes. Attention au temps de calcul !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisir la liste des méthodes \n",
    "# l'effort d'optimisation\n",
    "# Initialiser le générateur et \n",
    "# fixer le nombre d'itérations\n",
    "models=c(\"gbm\",\"rf\",\"xgbTree\")\n",
    "noptim=c(6,6,6)\n",
    "Niter=10 ; Init=11\n",
    "pred.spam=pred.autom(X,Y,methodes=models,N=Niter,xinit=Init,size=noptim,type=\"prob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis calculer et représenter les erreurs pour les méthodes considérées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des taux de bien classés\n",
    "obs=pred.spam$obs\n",
    "prev.spam=pred.spam$pred\n",
    "res.spam=lapply(prev.spam,function(x)apply((x>0.5)==(obs==1),2,mean))\n",
    "# Moyennes des taux de bien classés par méthode\n",
    "lapply(res.spam,mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distributions des taux de bien classés\n",
    "boxplot(data.frame(res.spam))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les commandes suivantes concernent les courbes ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apprécier la faible dispersion des \n",
    "# courbes ROC associées aux forêts aléatoires\n",
    "plot(perfroc.spam$rf,col=2)\n",
    "plot(perfroc.spam$rf,col=1,add=TRUE,lwd=2,avg=\"vertical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparaison des méthodes par le \n",
    "# tracer des courbes ROC moyennes\n",
    "# Problème pas identifié avec rlogit !\n",
    "predroc.spam=lapply(prev.spam,function(x)prediction(x,obs==1))\n",
    "perfroc.spam=lapply(predroc.spam,function(x)performance(x,\"tpr\",\"fpr\"))\n",
    "plot(perfroc.spam$gbm,col=1,lwd=2,avg=\"vertical\")\n",
    "plot(perfroc.spam$rf,col=2,add=TRUE,lwd=2,avg=\"vertical\")\n",
    "plot(perfroc.spam$xgbTree,col=3,add=TRUE,lwd=3,avg=\"vertical\")\n",
    "legend(\"bottomright\",legend=c(\"boost\",\"RF\",\"xgbTree\"),col=c(1:3),pch=\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quelle méthode semble finalement la plus pertinente? \n",
    "\n",
    "**Q** Que suggérer à Georges pour améliorer son détecteur de pourriel? Comment éviter que vos messages ne soient \"mangés\" par les anti-spams ?\n",
    "\n",
    "La plupart des détecteurs de spams sont des classifieurs bayésiens \"améliorés\". Consulter le [site Wikipedia](http://fr.wikipedia.org/wiki/Filtrage_bayésien_du_spam) à ce sujet. \n",
    "\n",
    "**Q** Quelle est la raison principale de ce choix de classifieur ? Quel est le problème rencontré ici, comment est-il résolu par ces détecteurs.\n",
    "\n",
    "## Annexe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred.autom=function(X,Y,p=1/2,methodes=c(\"knn\",\n",
    "   \"rf\"),size=c(10,2),xinit=11,N=10,typerr=\"cv\",\n",
    "   number=4,type=\"raw\") {\n",
    "# Fonction de prévision de N échantillons tests\n",
    "# par une liste de méthodes de régression \n",
    "# ou classification (uniquement 2 classes)\n",
    "# Optimisation des paramètres par validation \n",
    "# croisée (défaut) ou bootstrap ou... (cf. caret)\n",
    "# X : matrice ou frame des variables explicatives\n",
    "# Y : variable cible quantitative ou qualitative \n",
    "# p : proportion entre apprentissage et test\n",
    "# methodes : liste des méthodes de rdiscrimination\n",
    "# size : e grille des paramètres à optimiser\n",
    "# xinit : générateur de nombres aléatoires\n",
    "# N : nombre de réplications apprentissage / test\n",
    "# typerr : \"cv\" ou \"boo\" ou \"oob\"\n",
    "# number : nombre de répétitions CV ou bootstrap\n",
    "# pred : liste des matrices de prévision\n",
    "# type d'erreur\n",
    "Control=trainControl(method=typerr,number=number)\n",
    "# initialisation du générateur \n",
    "set.seed(xinit)\n",
    "# liste de matrices stockant les prévisions\n",
    "# une par méthode\n",
    "inTrain=createDataPartition(Y,p=p,list=FALSE)\n",
    "ntest=length(Y[-inTrain])\n",
    "pred=vector(\"list\",length(methodes))\n",
    "names(pred)=methodes\n",
    "pred=lapply(pred,function(x)x=matrix(0,\n",
    "   nrow=ntest,ncol=N))\n",
    "obs=matrix(0,ntest,N)\n",
    "set.seed(xinit)\n",
    "for(i in 1:N) {  # N itérations\n",
    "# indices de l'échantillon d'apprentissage \n",
    "inTrain=createDataPartition(Y,p=p,list=FALSE)\n",
    "# Extraction des échantillons\n",
    "trainDescr=X[inTrain,]\n",
    "testDescr=X[-inTrain,]\n",
    "trainY=Y[inTrain]\n",
    "testY=Y[-inTrain]\n",
    "# stockage des observés de testY\n",
    "obs[,i]=testY\n",
    "# centrage et réduction des variables\n",
    "xTrans=preProcess(trainDescr)\n",
    "trainDescr=predict(xTrans,trainDescr)\n",
    "testDescr=predict(xTrans,testDescr)\n",
    "# estimation et optimisation des modèles \n",
    "# pour chaque méthode de la liste\n",
    "for(j in 1:length(methodes)) {\n",
    "# modélisation \n",
    "modFit = train(trainDescr, trainY,\n",
    "   method = methodes[j], tuneLength = size[j],\n",
    "   trControl = Control)\n",
    "# prévisions\n",
    "if (type==\"prob\")  pred[[j]][,i]=predict(modFit,\n",
    "    newdata = testDescr,type=type)[,1]\n",
    "else pred[[j]][,i]=predict(modFit, \n",
    "   newdata = testDescr)\n",
    "}}\n",
    "list(pred=pred,obs=obs) # résultats\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
