{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"http://www.insa-toulouse.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/logo-insa.jpg\" style=\"float:left; max-width: 120px; display: inline\" alt=\"INSA\"/></a> \n",
    "\n",
    "<a href=\"http://wikistat.fr/\" ><img src=\"http://www.math.univ-toulouse.fr/~besse/Wikistat/Images/wikistat.jpg\" style=\"float:right; max-width: 250px; display: inline\"  alt=\"Wikistat\"/></a>\n",
    "\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Scénarios d'Apprentissage Statistique](https://github.com/wikistat/Apprentissage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRC: Score d'appétence d'un produit bancaire  avec <a href=\"https://cran.r-project.org/\"><img src=\"https://cran.r-project.org/Rlogo.svg\" style=\"max-width: 40px; display: inline\" alt=\"R\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Résumé\n",
    "Les données sont composées de 825 clients d'une banque décrits par 32 variables concernant leurs avoirs, et utilisations de leurs comptes. Après avoir réalisé, avec [R](https://github.com/wikistat/Exploration/blob/master/GRC-carte_Visa/Explo-R-Visa.ipynb) ou [Python](https://github.com/wikistat/Exploration/blob/master/GRC-carte_Visa/Explo-Python-Visa.ipynb), le premier objectif de segmentation ou profilage des types de comportement des clients, le 2ème consiste à estimer puis prévoir un *score d'appétence* pour un produit bancaie, ici la carte visa premier. Comparaison des différentes méthodes et algorihtmes d'apprentissage pour atteindre cet objectif de la régression logistique au *boosting* (*extrem gradient*) en passant par les arbres, les SVM ou random forest. Une procédure de validation croisée généralisée est itérée sur une selection de ces méthodes. Celles d'agrégation de modèles conduisent aux meilleurs résultats.\n",
    "\n",
    "## Introduction\n",
    "### Objectif\n",
    "Un  [calepin]((https://github.com/wikistat/Exploration/blob/master/GRC-carte_Visa/Explo-R-Visa.ipynb)), qu'il est préférable d'exécuter préalablement, décrit le premier objectif d'exploration puis segmentation ou profilage des types de comportement des clients d'une banque. \n",
    "\n",
    "Ce deuxième calepin propose de construire un [score d'appétence](http://www.math.univ-toulouse.fr/~besse/Wikistat/pdf/st-scenar-app-visa.pdf) pour la carte *Visa Premier*. Ce deuxième objectif est intégré à la saison 3 ([Apprentissage Statistique](https://github.com/wikistat/Apprentissage)). Il s'agit d'un score d'appétence mais ce pourrait être le score d'attrition (*churn*) d'un opérateur téléphonique ou encore un score de défaillance d'un emprunteur ou de faillite d'une entreprise; les outils de modélisation sont les mêmes et sont très largement utilisés dans tout le secteur tertiaire pour l'aide à la décision.\n",
    "\n",
    "Remarque: un [scénario](https://www.math.univ-toulouse.fr/~besse/Wikistat/pdf/st-scenar-app-visa.pdf) plus ancien propose une exécution avec SAS, encore utilisé dans de nombreuses grandes entreprises, et la comparaion des résultats obtenus avec R. Il propose également de tester l'[analyse discriminante](http://wikistat.fr/pdf/st-m-app-add.pdf) pas reprise dans ce calepin car les résultats sont en retrait vis-à-vis des autres méthodes.\n",
    "\n",
    "\n",
    "### Présentation des données\n",
    "#### Les variables\n",
    "La liste des variables est issue d'une base de données retraçant l'historique mensuel bancaire et les caractéristiques de tous les clients. Un sondage a été réalisé afin d'alléger les traitements ainsi qu'une première sélection de variables. Les variables contenues dans le fichier initial sont décrites dans le tableau ci-dessous. Elles sont observées sur 1425 clients.\n",
    "\n",
    "*Tableau: Liste des variables initiales et de leur libellé* Attention, certains sont écrits en majuscules dans les programmes puis en minuscules après transfomation des données (logarithme, recodage) au cours d ela phase d'exploration. Les noms des variables logarithmes des variables quantitatives se terminent par `L`les variables qualitatives se terminent par `Q`ou `q`. \n",
    "\n",
    "**Identifiant** | **Libellé**\n",
    "           --|--\n",
    "`sexeq` | Sexe (qualitatif) \n",
    "`ager` | Age en années\n",
    "`famiq` | Situation familiale: `Fmar Fcel Fdiv Fuli Fsep Fveu`\n",
    "`relat` | Ancienneté de relation en mois\n",
    "`pcspq` | Catégorie socio-professionnelle (code num)\n",
    "`opgnb` | Nombre d'opérations par guichet dans le mois\n",
    "`moyrv` | Moyenne des mouvements nets créditeurs des 3 mois en Kf\n",
    "`tavep` | Total des avoirs épargne monétaire en francs\n",
    "`endet` | Taux d'endettement\n",
    "`gaget` | Total des engagements en francs\n",
    "`gagec` | Total des engagements court terme en francs\n",
    "`gagem` | Total des engagements moyen terme en francs\n",
    "`kvunb` | Nombre de comptes à vue\n",
    "`qsmoy` | Moyenne des soldes moyens sur 3 mois\n",
    "`qcred` | Moyenne des mouvements créditeurs en Kf\n",
    "`dmvtp` | Age du dernier mouvement (en jours)\\hline\n",
    "`boppn` | Nombre d'opérations à M-1\n",
    "`facan` | Montant facturé dans l'année en francs\n",
    "`lgagt` | Engagement long terme\n",
    "`vienb` | Nombre de produits contrats vie\n",
    "`viemt` | Montant des produits contrats vie en francs\n",
    "`uemnb` | Nombre de produits épargne monétaire\n",
    "`xlgnb` | Nombre de produits d'épargne logement\n",
    "`xlgmt` | Montant des produits d'épargne logement en francs\n",
    "`ylvnb` | Nombre de comptes sur livret\n",
    "`ylvmt` | Montant des comptes sur livret en francs\n",
    "`rocnb` | Nombre de paiements par carte bancaire à M-1\n",
    "`nptag` | Nombre de cartes point argent\n",
    "`itavc` | Total des avoirs sur tous les comptes\n",
    "`havef` | Total des avoirs épargne financière en francs\n",
    "`jnbjd | Nombre de jours à débit à M\n",
    "**`carvp`** | **Possession de la carte VISA Premier**\n",
    "\n",
    "\n",
    "**Réponde aux questions en s'aidant des résultats des exécutions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Préparation des données\n",
    "### Lecture \n",
    "Les données sont disponibles dans le répertoire de ce calepin et chargées en même temps. Elles sont issues de la première phase de [prétraitement](https://github.com/wikistat/Exploration/blob/master/GRC-carte_Visa/Explo-R-Visa.ipynb) ou *data munging* pour détecter, corriger les erreurs et incohérences, éliminer des redondances, traiter les données manquantes, transformer certaines variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visaData=read.table(\"vispremv.dat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Combien d'individus et combien de variables sont concernées? \n",
    "\n",
    "Vérifier ci-dessous que la plupart des variables ont deux versions, l'une quantitative et l'autre qualitative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var=names(visaData)\n",
    "var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deux bases sont constituées: une contenant les variables explicatives initiales: qualitatives (csp, sexe, famille) et quantitatives , une autre celles qualitatives obtenues après recodage, les deux intègrent la variable à modéliser `CARVP`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varquant=var[c(1:3,26:54)]\n",
    "varqual=var[c(1:25,54)]\n",
    "visaDataR=visaData[,varquant]\n",
    "visaDataQ=visaData[,varqual]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types de variables\n",
    "Comme annoncé ci-dessus, la plupart des variables apparaissent deux fois: sous forme quantitative ou qualitative. Ainsi, la variable `AGER` est quantitative en années tandis que `ageq` est qualitative, de type facteur à trois niveaux. Ceci permet de s’adapter facilement à certaines méthodes qui n’acceptent que des variables explicatives quan-\n",
    "titatives. Néanmoins, le choix de découper en classe une variable quantitative peut avoir un impact important sur la qualité de la prévision de certaines méthodes:\n",
    "- le nombre de degrés de liberté diminue avec le nombre de modalités donc la qualité de l’estimation peut se dégrader pour de petits échantillons. Néanmoins, \n",
    "- le  découpage  en  classes  revient à considérer une approximation d’une transformation non-linéaire de la variable par une fonction étagée et peut améliorer l'ajustement du modèle.\n",
    "\n",
    "Cette possibilité impacte une méthode comme la régression logistique mais peut nuire à la construction d'un arbre qui recherche par construction des segmentations \"optimales\" des ensembles de valeurs. \n",
    "\n",
    "Il reste à comparer les stratégies pour retenir celle conduisant à la meilleure prévision.\n",
    "\n",
    "### Extraction des échantillons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xxx=111  # modifer cette valeur\n",
    "set.seed(xxx)\n",
    "# modifier 111\n",
    "npop=nrow(visaData)\n",
    "# tirage de 200 indices sans remise\n",
    "testi=sample(1:npop,200)\n",
    "#Liste des indices restant qui n’ont pas été tirés\n",
    "appri=setdiff(1:npop,testi)\n",
    "# Extraction échantillons d’apprentissage\n",
    "visApptQ=visaDataQ[appri,]\n",
    "visApptR=visaDataR[appri,]\n",
    "# Extraction échantillons de test\n",
    "visTestQ=visaDataQ[testi,]\n",
    "visTestR=visaDataR[testi,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Régression logistique](http://wikistat.fr/pdf/st-m-app-rlogit.pdf)\n",
    "Cette ancienne méthode reste toujours très utilisée. D'abord par habitude mais aussi par efficacité pour le traitement de données très volumineuses lors de l'estimation de très gros modèles (beaucoup de variables) notamment chez Criteo ou CDiscount. Elle est étudiée de façon plus détaillée pour comparer les deux stratégies: sur variables quantitatives ou qualitatives.\n",
    "\n",
    "Pluasieurs algorithmes de [sélection de variables](http://wikistat.fr/pdf/st-m-app-linSelect.pdf) peuvent être testés: ceux *forward*, *backward*, *step-wise* en minimisant le critère AIC ou encore les algorithmes avec pénalisation *ridge* Lasso ou *elastic net*.\n",
    "\n",
    "Ces derniers algorihtmes de sélection par pénalisation sont testés de manière plus approfondie dans la version Python de ce scénario. Seule la sélection *step-wise* est testée pour simplifier les comparaisons. Les interactions ne sont pas prises en compte. Certains services ont pour pratique de mixer arbre de classification et régression logistique pour sélectionner et intégrer les interactions les plus évidentes: Les premières segmentations d'un arbre de décision déterminent une nouvelle variable qui est intégrée à la régression logistique.\n",
    "\n",
    "### Variables initiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varquant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modèle trivial de départ avec le seul terme constant\n",
    "visaR.logit=glm(CARVP~1,data=visApptR,family=binomial,na.action=na.omit)\n",
    "# sélection step-wise\n",
    "# le paramètre trace=0 peut être enlevé pour suivre la progression\n",
    "visaR.step=step(visaR.logit,direction=\"both\",scope=list(lower=~1, upper=~SEXEQ+FAMIQ+PCSPQ+RELAT+AGER+OPGNBL+\n",
    "                MOYRVL+TAVEPL+ENDETL+GAGETL+GAGECL+GAGEML+KVUNB+QSMOY+QCREDL+DMVTPL+BOPPNL+FACANL+LGAGTL+\n",
    "                VIENB+VIEMTL+UEMNB+XLGNB+XLGMTL+YLVNB+YLVMTL+ROCNB+NPTAG+ITAVCL+HAVEFL+JNBJDL), trace=0)\n",
    "# observer les p-valeurs\n",
    "anova(visaR.step,test=\"Chisq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimation de l'erreur par validation croisée puis sur l'échantillon test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.glm(visApptR,visaR.step,K=10)$delta[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predTestR=predict(visaR.step,newdata=visTestR)>0.5\n",
    "table(predTestR,visTestR$CARVP==\"Coui\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables qualitatives après recodage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varqual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modèle trivial de départ avec le seul terme constant\n",
    "visaQ.logit=glm(CARVP~1,data=visApptQ,family=binomial,na.action=na.omit)\n",
    "# sélection step-wise\n",
    "# le paramètre trace=0 peut être enlevé pour suivre la progression\n",
    "visaQ.step=step(visaQ.logit,direction=\"both\",scope=list(lower=~1, upper=~SEXEQ +FAMIQ +PCSPQ + kvunbq + vienbq+uemnbq + \n",
    "                xlgnbq+ylvnbq+rocnbq+nptagq + endetq + gagetq + facanq +lgagtq+ havefq + ageq+relatq + qsmoyq + opgnbq + \n",
    "                moyrvq + tavepq + dmvtpq + boppnq + jnbjdq + itavcq), trace=0)\n",
    "# observer les p-valeurs\n",
    "anova(visaQ.step,test=\"Chisq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quelles sont les variables importantes? Comment interpréter?\n",
    "\n",
    "Estimation de l'erreur de prévision par validation croisée puis sur l'échantillon test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.glm(visApptQ,visaQ.step,K=10)$delta[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predTestQ=predict(visaQ.step,newdata=visTestQ)>0.5\n",
    "table(predTestQ,visTestQ$CARVP==\"Coui\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Conclusions* (qui dépendent du choix de l'initialisation de xxx):\n",
    "\n",
    "**Q** quel modèle est le moins complexe (mois de paramètre)?\n",
    "\n",
    "**Q** Quel modèle est le plus simple à interpréter?\n",
    "\n",
    "**Q** Quel modèle prédit le mieux?\n",
    "\n",
    "## [Arbres binaires de décision](http://wikistat.fr/pdf/st-m-app-cart.pdf)\n",
    "Les arbres binaires de décision concurrencent la régression logistique et gardent une pace de choix dans le sservices de Gestion de la Relation Client, maintenant de Science des Données, par la facilité d'interprétation des modèles qui en découlent.  \n",
    "### Variables initiales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(rpart)\n",
    "visaR.tree=rpart(CARVP~.,data=visApptR,parms=list(split='information'),cp=0.001)\n",
    "# Choix élémentaire du coefficient de complexité\n",
    "options(repr.plot.width=8, repr.plot.height=4)\n",
    "plotcp(visaR.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Comment lire le graphique précédent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracé de l’arbre élagué\n",
    "visaR.treeOpt=prune(visaR.tree,cp=0.018)\n",
    "library(partykit)\n",
    "options(repr.plot.width=8, repr.plot.height=6)\n",
    "plot(as.party(visaR.treeOpt), type=\"simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quelles sont les variables importantes? Comment interpréter?\n",
    "\n",
    "### Variables qualitatives après recodage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visaQ.tree=rpart(CARVP~.,data=visApptQ,parms=list(split='information'),cp=0.001)\n",
    "# Choix élémentaire du coefficient de complexité\n",
    "options(repr.plot.width=8, repr.plot.height=4)\n",
    "plotcp(visaQ.tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tracé de l’arbre élagué\n",
    "visaQ.treeOpt=prune(visaQ.tree,cp=0.012)\n",
    "library(partykit)\n",
    "options(repr.plot.width=8, repr.plot.height=6)\n",
    "plot(as.party(visaQ.treeOpt), type=\"simple\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une procédure d'élagage par validation croisée serait sans doute plus précise. Elle est intégrée ci-après dan sla comparaison automatique utilisant le package `caret`.\n",
    "\n",
    "Erreurs de prévision sur le test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predTestR=predict(visaR.treeOpt,newdata=visTestR,type=\"class\")\n",
    "table(predTestR,visTestR$CARVP==\"Coui\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predTestQ=predict(visaQ.treeOpt,newdata=visTestQ,type=\"class\")\n",
    "table(predTestQ,visTestQ$CARVP==\"Coui\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparer les résultats\n",
    "\n",
    "**Q** Quel est le modèle le plus simple / facile à interpréter\n",
    "\n",
    "**Q** Quel est celui fournissant les meilleures prévisions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Courbes ROC](http://wikistat.fr/pdf/st-m-app-risque.pdf)\n",
    "La valeur de seuil par défaut (0.5) n'étant pas nécessairement celle \"optimale\", il est important de comparer les courbes ROC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ROCR)\n",
    "ROCdislogR=predict(visaR.step,newdata=visTestR)\n",
    "preddislogR=prediction(ROCdislogR,visTestR$CARVP==\"Coui\")\n",
    "perfdislogR=performance(preddislogR,\"tpr\",\"fpr\")\n",
    "\n",
    "ROCdislogQ=predict(visaQ.step,newdata=visTestQ)\n",
    "preddislogQ=prediction(ROCdislogQ,visTestQ$CARVP==\"Coui\")\n",
    "perfdislogQ=performance(preddislogQ,\"tpr\",\"fpr\")\n",
    "\n",
    "ROCdistreeR=predict(visaR.treeOpt,newdata=visTestR,type=\"prob\")[,2]\n",
    "preddistreeR=prediction(ROCdistreeR,visTestR$CARVP==\"Coui\")\n",
    "perfdistreeR=performance(preddistreeR,\"tpr\",\"fpr\")\n",
    "\n",
    "ROCdistreeQ=predict(visaQ.treeOpt,newdata=visTestQ,type=\"prob\")[,2]\n",
    "preddistreeQ=prediction(ROCdistreeQ,visTestQ$CARVP==\"Coui\")\n",
    "perfdistreeQ=performance(preddistreeQ,\"tpr\",\"fpr\")\n",
    "\n",
    "# tracer les courbes ROC en les superposant \n",
    "# pour mieux comparer\n",
    "plot(perfdislogR,col=1) \n",
    "plot(perfdislogQ,col=2,add=TRUE) \n",
    "plot(perfdistreeR,col=3,add=TRUE)\n",
    "plot(perfdistreeQ,col=4,add=TRUE)\n",
    "legend(\"bottomright\",legend=c(\"LogitR\",\"LogitQ\",\"TreeR\",\"TreeQ\"),col=c(1:4),pch=\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commenter les résultats.\n",
    "\n",
    "**Q** Intérêt de la régression logistique par rapport à un arbre.\n",
    "\n",
    "**Q** Conséquence du croisemen des courbes ROC sur l'évaluation AUC.\n",
    "\n",
    "L'échantillon test reste de taille modeste (200). une étude plus systématique est nécessaire ainsi que la prise en compte des autres méthodes;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Procédure automatique avec le package `caret`\n",
    "Un avantage de R est le nombre considérables d'utilisateurs qui participent au développement des librairies. cet avantage a un revers: le manque d'homogénéité de celles-ci. Pour y remédier dans les applications d'apprentissage machine, la (méta)librairie [`caret`](https://topepo.github.io/caret/) de [Max Kuhn (2008)](https://www.jstatsoft.org/article/view/v028i05) intègre dans un même usage, une même syntaxe, l'ensemble des fonctionnalités d'apprentissage et propose une approche unifiée des procédures d'optimisation des paramètres.\n",
    "\n",
    "De très nombreuses stratégies sont possibles. Il suffit de les mettre en oeuvre afin de comparer les qualités prédictives: considérer les seules variables initiales, celles transformées, la réunion des deux ensembles, les composantes issues de l'AFCM de l'[étape précédente](https://github.com/wikistat/Exploration/blob/master/GRC-carte_Visa/Explo-R-Visa.ipynb) ... à croiser avec plu sde 200 options et méthodes d'apprentissage de `caret`, considérer aussi `caretEnsemble` qui permet de combiner des modèles entre eux comme cela est courant pour les concours kaggle.\n",
    "\n",
    "Une sélection drastique est opérée en ne considérant que quelques méthodes parmi les grandes familles et sur les seules variables initiales.\n",
    "\n",
    "### Calcul parallèle\n",
    "Par ailleurs, même sous windows, `caret` offre simplement des possibilités de parallèlisation en utilisant la package `doParallel`. Même si les algorithmes des différentes méthodes d'apprentissage ne sont pas parallélisés, les itérations des calculs de validations croiser pour l'optimisation des paramètres sont effectivement parallélisés avec un gain de temps très appréciable fonciton du nombre de processeurs. Ceci est obtenu en exécutant les commandes suivantes en supposant que 4 processeurs sont disponibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(doParallel)\n",
    "cl <- makeCluster(4)\n",
    "registerDoParallel(cl) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Préparation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(caret)\n",
    "# extraction des données\n",
    "# Variable cible\n",
    "Y=visaData[,\"CARVP\"]\n",
    "# Variables explicatives\n",
    "X=visaData[,varquant[-32]]\n",
    "# Transformation des facteurs en indicatrices pour utiliser certains algorithmes\n",
    "# notamment xgboost\n",
    "library(FactoMineR)\n",
    "X=data.frame(tab.disjonctif(X[,c(1:3)]),X[,-c(1:3)])\n",
    "summary(Y);summary(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Préparation des échantillons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx=11 # Changer cette valeur pour personnaliser l'échantillonnage\n",
    "set.seed(xx)\n",
    "inTrain = createDataPartition(X[,1],p = 0.8, list = FALSE)\n",
    "# Extraction des échantillons\n",
    "trainDescr=X[inTrain,]\n",
    "testDescr=X[-inTrain,]\n",
    "testY=Y[-inTrain]\n",
    "trainY=Y[inTrain]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certaines méthodes sont sensibles à des effets de variance ou d'unité des variables. Il est préférable d'introduire une normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalisation calculée sur les paramètres de l'échantillon d'apprentissage\n",
    "xTrans=preProcess(trainDescr)\n",
    "trainDescr=predict(xTrans,trainDescr)\n",
    "# Puis appliquée également à l'échantillon test\n",
    "testDescr=predict(xTrans,testDescr)\n",
    "# Choix de la validation croisée\n",
    "cvControl=trainControl(method=\"cv\",number=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Pour chacun des modèles ou méthodes utilisés ci-dessous, identifier la méthode, préciser les paramètres associés et noter celui ou ceux optimisés par défaut par caret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 Régression logistique\n",
    "# Attention, la régression logistique sans interaction (linéaire) est estimée ci-dessous\n",
    "set.seed(2)\n",
    "rlogFit = train(trainDescr, trainY,method = \"glmStepAIC\", trace=FALSE)\n",
    "rlogFit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2 Arbre de décision\n",
    "set.seed(2)\n",
    "rpartFit = train(trainDescr, trainY, method = \"rpart\", tuneLength = 10,\n",
    "    trControl = cvControl)\n",
    "rpartFit\n",
    "plot(rpartFit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3 Réseau de neurones\n",
    "set.seed(2)\n",
    "nnetFit = train(trainDescr, trainY, method = \"nnet\", tuneLength = 6,\n",
    "                trControl = cvControl, trace=FALSE)\n",
    "nnetFit\n",
    "plot(nnetFit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#4 Random forest\n",
    "set.seed(2)\n",
    "rfFit = train(trainDescr, trainY,method = \"rf\", tuneLength = 8,\n",
    "              trControl = cvControl, trace=FALSE)\n",
    "rfFit\n",
    "plot(rfFit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 Boosting \n",
    "set.seed(2)\n",
    "gbmFit = train(trainDescr, trainY,method = \"gbm\", tuneLength = 8,\n",
    "               trControl = cvControl)\n",
    "gbmFit\n",
    "plot(gbmFit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 Extrême boosting\n",
    "set.seed(2)\n",
    "xgbFit = train(trainDescr, trainY,method = \"xgbTree\", tuneLength = 6,\n",
    "               trControl = cvControl, trace=FALSE)\n",
    "xgbFit\n",
    "plot(xgbFit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 SVM\n",
    "set.seed(2)\n",
    "svmFit = train(trainDescr, trainY,method = \"svmRadial\", tuneLength = 6,\n",
    "               trControl = cvControl, trace=FALSE)\n",
    "svmFit\n",
    "plot(svmFit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prévision et erreur de test\n",
    "Les méthodes sélectionnées et optimisées sont ensuite appliquées à la prévision de l’échantillon test. Estimation du taux de bien classés:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=list(logit=rlogFit,cart=rpartFit,nnet=nnetFit,rf=rfFit,gbm=gbmFit,xgb=xgbFit,svm=svmFit)\n",
    "testPred=predict(models, newdata = testDescr)\n",
    "# taux de bien classés\n",
    "lapply(testPred,function(x)mean(x==testY))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tracer  les  courbes  ROC  pour  analyser  spécificité  et  sensibilité  des  différentes  méthodes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(ROCR)\n",
    "models=list(logit=rlogFit,cart=rpartFit,nnet=nnetFit,rf=rfFit,gbm=gbmFit,xgb=xgbFit)\n",
    "testProb=predict(models, newdata = testDescr,type=\"prob\")\n",
    "predroc=lapply(testProb,function(x)prediction(x[,1],testY==\"Cnon\"))\n",
    "perfroc=lapply(predroc,\n",
    "function(x)performance(x, \"tpr\", \"fpr\"))\n",
    "plot(perfroc$logit,col=1)\n",
    "plot(perfroc$cart,col=2,add=TRUE)\n",
    "plot(perfroc$nnet,col=3,add=TRUE)\n",
    "plot(perfroc$rf,col=4,add=TRUE)\n",
    "plot(perfroc$gbm,col=5,add=TRUE)\n",
    "plot(perfroc$xgb,col=6,add=TRUE)\n",
    "legend(\"bottomright\",legend=c(\"logit\",\"CART\",\"nnet\",\"RF\",\"boost\",\"xgBoost\"),col=c(1:6),pch=\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Validation croisée *Monte Carlo*](http://wikistat.fr/pdf/st-m-app-risque-estim.pdf)\n",
    "L'échantillon est de faible taille (#200), et les estimations des taux de bien classés comme le tracé des courbes ROC sont très dépendants de l’échantillon test; on peut s’interroger sur l’identité du modèle le plus performant ainsi que sur la significativité des différences observées entre les méthodes. Il est donc important d’itérer le processus (validation croisée *Monte Carlo*) sur plusieurs échantillons tests. Exécuter la fonction en annexe en choisissant les méthodes semblant les plus performantes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisir la liste des méthodes et l’effort d’optimisation\n",
    "models=c(\"glmStepAIC\",\"rpart\",\"nnet\",\"rf\",\"gbm\",\"xgbTree\")\n",
    "noptim=c(6,6,6,6,6,6)\n",
    "# Initialiser le générateur et fixer le nombre d’itérations\n",
    "# Changer ces valeurs. Attention au temps de calcul! Être patient!\n",
    "Niter=3 ; Init=11  \n",
    "# Appel de la fonction définie en annexe\n",
    "pred.ozone=pred.autom(X,Y,methodes=models,N=Niter,xinit=Init,size=noptim,type=\"prob\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puis calculer et représenter les erreurs pour les méthodes considérées"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul des taux de bien classés\n",
    "obs=pred.ozone$obs\n",
    "prev.ozone=pred.ozone$pred\n",
    "res.ozone=lapply(prev.ozone,function(x)apply((x>0.5)==(obs==1),2,mean))\n",
    "# Moyennes des taux de bien classés par méthode\n",
    "lapply(res.ozone,mean)\n",
    "# distributions des taux de bien classés\n",
    "boxplot(data.frame(res.ozone))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les commandes suivandes tracent les courbes ROC moyennes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Comparaison des méthodes par le\n",
    "# tracer des courbes ROC moyennes\n",
    "# Problème pas identifié avec rlogit!\n",
    "predroc.ozone=lapply(prev.ozone,function(x)prediction(x,obs==1))\n",
    "perfroc.ozone=lapply(predroc.ozone,function(x)performance(x,\"tpr\",\"fpr\"))\n",
    "plot(perfroc.ozone$gbm,col=1,lwd=2,avg=\"vertical\")\n",
    "plot(perfroc.ozone$rf,col=2,add=TRUE,lwd=1.5,avg=\"vertical\")\n",
    "plot(perfroc.ozone$nnet,add=TRUE,col=3,lwd=1.5,avg=\"vertical\")\n",
    "plot(perfroc.ozone$xgbTree,add=TRUE,col=4,lwd=2,avg=\"vertical\")\n",
    "plot(perfroc.ozone$glmStepAIC,add=TRUE,col=5,lwd=1.5,avg=\"vertical\")\n",
    "legend(\"bottomright\",legend=c(\"boost\",\"RF\", \"nnet\",\"xgBoost\",\"logit\"),col=c(1:5),pch=\"_\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Q** Quelle méthode retenir, en fonction du taux de faux positif acceptable, pour prévoir le dépassement du seuil? Et si le comanditaire veut une solution explicable?\n",
    "\n",
    "\n",
    "*N.B.* L'algorithme `xgboost` nécessiterait des efforts plus important d'optimisation des paramètres.\n",
    "\n",
    "## Annexe: Fonction de validation croisée *Monte Carlo*\n",
    "*N* réplications des estimations / prévisions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred.autom=function(X,Y,p=1/2,methodes=c(\"knn\",\n",
    "\"rf\"),size=c(10,2),xinit=11,N=10,typerr=\"cv\",\n",
    "number=4,type=\"raw\") {\n",
    "# Fonction de prévision de N échantillons tests\n",
    "# par une liste de méthodes de régression\n",
    "# ou classification (uniquement 2 classes)\n",
    "# Optimisation des paramètres par validation\n",
    "# croisée (défaut) ou bootstrap ou... (cf. caret)\n",
    "# X : matrice ou frame des variables explicatives\n",
    "# Y : variable cible quantitative ou qualitative\n",
    "# p : proportion entre apprentissage et test\n",
    "# methodes : liste des méthodes de rdiscrimination\n",
    "# size : e grille des paramètres à optimiser\n",
    "# xinit : générateur de nombres aléatoires\n",
    "# N : nombre de réplications apprentissage/test\n",
    "# typerr : \"cv\" ou \"boo\" ou \"oob\"\n",
    "# number : nombre de répétitions CV ou bootstrap\n",
    "# pred : liste des matrices de prévision\n",
    "# type d’erreur\n",
    "Control=trainControl(method=typerr,number=number)\n",
    "# initialisation du générateur\n",
    "set.seed(xinit)\n",
    "# liste de matrices stockant les prévisions\n",
    "# une par méthode\n",
    "inTrain=createDataPartition(Y,p=p,list=FALSE)\n",
    "ntest=length(Y[-inTrain])\n",
    "pred=vector(\"list\",length(methodes))\n",
    "names(pred)=methodes\n",
    "pred=lapply(pred,function(x)x=matrix(0,\n",
    "nrow=ntest,ncol=N))\n",
    "obs=matrix(0,ntest,N)\n",
    "set.seed(xinit)\n",
    "for(i in 1:N) {\n",
    "# N itérations\n",
    "# indices de l’échantillon d’apprentissage\n",
    "inTrain=createDataPartition(Y,p=p,list=FALSE)\n",
    "# Extraction des échantillons\n",
    "trainDescr=X[inTrain,]\n",
    "testDescr=X[-inTrain,]\n",
    "trainY=Y[inTrain]\n",
    "testY=Y[-inTrain]\n",
    "# stockage des observés de testY\n",
    "obs[,i]=testY\n",
    "# centrage et réduction des variables\n",
    "xTrans=preProcess(trainDescr)\n",
    "trainDescr=predict(xTrans,trainDescr)\n",
    "testDescr=predict(xTrans,testDescr)\n",
    "# estimation et optimisation des modèles\n",
    "# pour chaque méthode de la liste\n",
    "for(j in 1:length(methodes)) {\n",
    "# modélisation\n",
    "modFit = train(trainDescr, trainY,method = methodes[j], tuneLength = size[j],\n",
    "               trControl = Control)\n",
    "# prévisions\n",
    "if (type==\"prob\")  pred[[j]][,i]=predict(modFit,\n",
    "newdata = testDescr,type=type)[,1]\n",
    "else pred[[j]][,i]=predict(modFit,\n",
    "newdata = testDescr)\n",
    "}}\n",
    "list(pred=pred,obs=obs)\n",
    "# résultats\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
